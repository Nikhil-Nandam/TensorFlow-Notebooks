{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhil-Nandam/TensorFlow-Notebooks/blob/main/02_neural_network_classification_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqNgME2lu3pN"
      },
      "source": [
        "# Introduction to neural network classification with TensorFlow\n",
        "\n",
        "In this notebook, we're going to learn how to write neural networks for classification problems.\n",
        "\n",
        "A classification is when you try to classify something as one thing or another.\n",
        "\n",
        "A few types of classification problems:\n",
        "* Binary classification\n",
        "* Multiclass classfication\n",
        "* Multilabel classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv0y8UTavQrZ"
      },
      "source": [
        "## Creating data to view and fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc8nDo_U0zL_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "# Make 1000 examples\n",
        "n_samples = 1000\n",
        "\n",
        "# Create circles\n",
        "X, y = make_circles(n_samples, noise=0.03, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCQLNPdD1qLO"
      },
      "outputs": [],
      "source": [
        "# Check out the features\n",
        "X, X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZZiwwWd2KKi"
      },
      "outputs": [],
      "source": [
        "# Check the labels\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR9Vizj52hdQ"
      },
      "outputs": [],
      "source": [
        "np.count_nonzero(y==1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data is a little hard to understand right now... let's visualize it!"
      ],
      "metadata": {
        "id": "0NjjQMw33PKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "circles = pd.DataFrame({\"X0\": X[:, 0], \"X1\": X[:, 1], \"label\": y})\n",
        "circles"
      ],
      "metadata": {
        "id": "DfZY2sgE67Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "circles[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "XfQ_t0c7P8X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize with a plot\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu)"
      ],
      "metadata": {
        "id": "bj9FHqoj7J-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ›  **Exercise:** Before pushing forward, spend 10-minutes playing ariund with [playground.tensorflow.org](http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.08000&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) building and running different neural networks. See what happens when you change different hyperparameters."
      ],
      "metadata": {
        "id": "Hr3QbHQI7iuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and Output shapes"
      ],
      "metadata": {
        "id": "y8e3r8rqKGEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of our features and labels\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "nuVKcuF-KbEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples we are working with\n",
        "len(X), len(y)"
      ],
      "metadata": {
        "id": "p43uLL2eKgBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first example of features and labels\n",
        "X[0], y[0]"
      ],
      "metadata": {
        "id": "R6q0rPdiKhVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in modelling\n",
        "\n",
        "The steps in modelling with TensorFlow are typically:\n",
        "\n",
        "1. Create or import a model\n",
        "2. Compile the model\n",
        "3. Fit the model\n",
        "4. Evaluate the model\n",
        "5. Tweak \n",
        "6. Evaluate..."
      ],
      "metadata": {
        "id": "JtAvYvGkKrSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "id": "iSfaHnuzN435"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model using the Sequential API\n",
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(X, y, epochs=5)"
      ],
      "metadata": {
        "id": "3AxAyZplK0kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try and improve our model by training for longer...\n",
        "model_1.fit(X, y, epochs=200, verbose=0)\n",
        "model_1.evaluate(X, y)"
      ],
      "metadata": {
        "id": "cleLmCSpOIzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we're working on a binary classification problem and our model is getting around ~50% accuracy... it's performing as if it's guessing.\n",
        "\n",
        "So let's step things up a notch and add an extra layer."
      ],
      "metadata": {
        "id": "x3M3FDhlOxRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(X, y, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "QB-z5BSrO0Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate the model\n",
        "model_2.evaluate(X, y)"
      ],
      "metadata": {
        "id": "sGrbsvqmPnLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "circles[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "EyNqHtuTPxBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "\n",
        "Let's look into our bag of tricks to see how we can improve our model.\n",
        "\n",
        "1. Create a model - we might want to add more layers or increase the number of hidden units within a layer.\n",
        "2. Compiling a model - here we might want to choose a different optimization function such as Adam instead of SGD.\n",
        "3. Fitting a model - perhaps we might want our model to train for longer."
      ],
      "metadata": {
        "id": "mZhDcr6jQxEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (this time 3 layers)\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),     # add 100 dense neurons\n",
        "    tf.keras.layers.Dense(10),      # add another layer with 10 neurons\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(X, y, epochs=100, verbose=0)"
      ],
      "metadata": {
        "id": "aO2r5tTGRffQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate the model\n",
        "model_3.evaluate(X, y)"
      ],
      "metadata": {
        "id": "KN6a0VYmS1d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.predict(X)"
      ],
      "metadata": {
        "id": "ngV13amPS6N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”‘ **Note:** Whenever your model is performing strangely or there's something going on with your data you're not quite sure of, remember these three words: **visualize, visualize, visualize**. Inspect your data, inspect your model, inpsect your model's predictions.\n",
        "\n",
        "To visualize our model's predictions, let's create a function `plot_decision_boundary()`, this function will:\n",
        "\n",
        "* Take in a trained model, features (X) and labels (y).\n",
        "* Create a meshgrid of the different X values.\n",
        "* Make predictions across the meshgrid.\n",
        "* Plot the predictions as well as a line between zones (where each unique class falls)"
      ],
      "metadata": {
        "id": "D-lCWpkmT7OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def plot_decision_boundary(model, X, y):\n",
        "    \"\"\"\n",
        "    Plot the decision boundary created by a model predicting on X.\n",
        "    This function was inspired by 2 resources:\n",
        "        1. CS231n - https://cs231n.github.io/neural-networks-case-study/\n",
        "        2. Made with ML basics - https://github.com/GokuMohandas/MadeWithML/blob/main/notebooks/08_Neural_Networks.ipynb\n",
        "    \"\"\"\n",
        "    # Define the axis boundaries of the plot and create a meshgrid\n",
        "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
        "                         np.linspace(y_min, y_max, 100))\n",
        "    \n",
        "    # Create X values (we're going to make predictions on these)\n",
        "    x_in = np.c_[xx.ravel(), yy.ravel()]    # stack 2D arrays together\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(x_in)\n",
        "\n",
        "    # Check for multiclass\n",
        "    if len(y_pred[0]) > 1:\n",
        "        print(\"Doing multiclass classification\")\n",
        "        # We have to reshape our prediction to get them ready for plotting\n",
        "        y_pred = np.argmax(y_pred, axis=1).reshape(xx.shape)\n",
        "    else:\n",
        "        print(\"Doing binary classification\")\n",
        "        y_pred = np.round(y_pred).reshape(xx.shape)\n",
        "\n",
        "    # Plot the decision boundary\n",
        "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())"
      ],
      "metadata": {
        "id": "zMSPMiAQUmGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the predictions our model is making\n",
        "plot_decision_boundary(model=model_3, X=X, y=y)"
      ],
      "metadata": {
        "id": "lPDxoJkHWnNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see of our model can be used for a regression problem...\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create some regression data\n",
        "X_regression = tf.range(0, 1000, 5)\n",
        "y_regression = tf.range(100, 1100, 5)   # y = X + 100\n",
        "\n",
        "# Split our regression data into training and test sets\n",
        "X_reg_train = X_regression[:150]\n",
        "X_reg_test = X_regression[150:]\n",
        "y_reg_train = y_regression[:150]\n",
        "y_reg_test = y_regression[150:]\n",
        "\n",
        "# Fit our model to the regression data\n",
        "model_3.fit(X_reg_train, y_reg_train, epochs=100)"
      ],
      "metadata": {
        "id": "OCuTyXXwXPLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oh wait... we compiled our model for a binary classification problem.\n",
        "\n",
        "But... we're working on a regression problem, let's change the model to suit our data."
      ],
      "metadata": {
        "id": "EjInf6zkbLpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Dense(1),\n",
        "])\n",
        "\n",
        "# 2. Compile the model, this time with regression specific loss function\n",
        "model_3.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(tf.expand_dims(X_reg_train, axis=-1), y_reg_train, epochs=100)"
      ],
      "metadata": {
        "id": "WP7_6pSlZwV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with our trained model\n",
        "y_reg_preds = model_3.predict(X_reg_test)\n",
        "\n",
        "# Plot the model's predictions against our regression data\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(X_reg_train, y_reg_train, c=\"b\", label=\"Training data\")\n",
        "plt.scatter(X_reg_test, y_reg_test, c=\"g\", label=\"Test data\")\n",
        "plt.scatter(X_reg_test, y_reg_preds, c=\"r\", label=\"Predictions\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "WaPKaZaldNFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The missing piece: Non-linearity"
      ],
      "metadata": {
        "id": "xfL5irM0eFII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_4 = tf.keras.Sequential([\n",
        "    # tf.keras.layers.Dense(1, activation=\"linear\")\n",
        "    tf.keras.layers.Dense(1, activation=tf.keras.activations.linear)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "hisotry = model_4.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "kRwwbeUxg6d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our data\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu)"
      ],
      "metadata": {
        "id": "H6KHuHNEjVnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the decision boundary for our latest model\n",
        "plot_decision_boundary(model=model_4, X=X, y=y)"
      ],
      "metadata": {
        "id": "9mtbWOSQj--X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try build our first neural netwrok with non-linear activation function."
      ],
      "metadata": {
        "id": "_cVQyirwkvna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model with a non-linear activation\n",
        "model_5 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, activation=tf.keras.activations.relu)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_5.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = model_5.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "qNzHHdXakIV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Time to replicate the muli-layer neural network from TensorFlow playground\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_6 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_6.fit(X, y, epochs=250)"
      ],
      "metadata": {
        "id": "1myv3wNTlelb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model_6.evaluate(X, y)"
      ],
      "metadata": {
        "id": "1zTm6qEDpqq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How do our model predictions look?\n",
        "plot_decision_boundary(model_6, X, y)"
      ],
      "metadata": {
        "id": "FLRCVRI-pwz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_7 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_7.fit(X, y, epochs=100)"
      ],
      "metadata": {
        "id": "oXw-7_qUqMUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate our model\n",
        "model_7.evaluate(X, y)"
      ],
      "metadata": {
        "id": "Vt5MhGzWr_wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize our incredible metrics\n",
        "plot_decision_boundary(model_7, X, y)"
      ],
      "metadata": {
        "id": "mATd_6mCrZO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ¤” **Question:** What's wrong with predictions we've made? Are we really evaluating our model correclty? Hint: What data did the model learn on and what data did we predict on?\n",
        "\n",
        "ðŸ”‘ **Note:** The combination of **linear (straight lines) and non-linear (non-straight lines) functions** is one of the key fundamentals of neural networks.\n",
        "\n",
        "Now we've discussed the concept of linear and non-linear function (or lines), let's see them in action"
      ],
      "metadata": {
        "id": "ia7xptXCrb3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a toy tensor (similar to the data we pass into our models)\n",
        "A = tf.cast(tf.range(-10, 10), tf.float32)\n",
        "A"
      ],
      "metadata": {
        "id": "wm3V73ZsskVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize our toy tensor\n",
        "plt.plot(A);"
      ],
      "metadata": {
        "id": "gsjvvl9YLsVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's start by replicating sigmoid - sigmoid(x) = 1 / (1 + exp(-x))\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + tf.exp(-x))\n",
        "\n",
        "# Use the sigmoid function on our toy tensor\n",
        "sigmoid(A)"
      ],
      "metadata": {
        "id": "jpmL6AgbM1oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot out toy tensor transformed by sigmoid\n",
        "plt.plot(sigmoid(A));"
      ],
      "metadata": {
        "id": "DV_3g0cbOMss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's recreate the relu function\n",
        "def relu(x):\n",
        "    return tf.maximum(0, x)\n",
        "\n",
        "# Pass our toy tensor to our custom relu function\n",
        "relu(A)"
      ],
      "metadata": {
        "id": "abVFcLlsOS13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot relu modified tensor\n",
        "plt.plot(relu(A));"
      ],
      "metadata": {
        "id": "KeGrutYWO9Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try the linear activation function\n",
        "tf.keras.activations.linear(A)"
      ],
      "metadata": {
        "id": "7fu8W2R6PK8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Does the linear activation function change anything?\n",
        "plt.plot(tf.keras.activations.linear(A))"
      ],
      "metadata": {
        "id": "SETbFttlPsQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Does A even change?\n",
        "A == tf.keras.activations.linear(A)"
      ],
      "metadata": {
        "id": "x4hXhPFzP1iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating and improving our classification\n",
        "\n",
        "So far we've been training and testing on the same dataset...\n",
        "\n",
        "However, in Machine Learning this is basically a sin.\n",
        "\n",
        "So, let's create a training and test set."
      ],
      "metadata": {
        "id": "8j4Z0AjgP6aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many examples we have\n",
        "len(X)"
      ],
      "metadata": {
        "id": "l_Ewgpt4Q3vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and test sets\n",
        "X_train, y_train = X[:800], y[:800]\n",
        "X_test, y_test = X[800:], y[800:]\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "UOLamZagRfG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's recreate a model to find on the training data and evaluate on the test data.\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model (same as model_7)\n",
        "model_8 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_8.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = model_8.fit(X_train, y_train, epochs=25)"
      ],
      "metadata": {
        "id": "xEl1eq72RwfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate the model on the test dataset\n",
        "model_8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "SH76SmhfTW2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundaries for the training and test sets\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Train\")\n",
        "plot_decision_boundary(model_8, X=X_train, y=y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Test\")\n",
        "plot_decision_boundary(model_8, X=X_test, y=y_test)"
      ],
      "metadata": {
        "id": "kcllr9GyTquK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the loss (or training) curves"
      ],
      "metadata": {
        "id": "s-ycPuwVUC6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the history object into a DataFrame\n",
        "pd.DataFrame(history.history)"
      ],
      "metadata": {
        "id": "Rj99qYX1UlYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss curves\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.title(\"Model_8 loss curves\");"
      ],
      "metadata": {
        "id": "Imp-LKquVE-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”‘ **Note:** For many problems, the loss function going down means the model is improving (the predictions it's making are getting closer to the ground truth labels)."
      ],
      "metadata": {
        "id": "WuaFyWppVa_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the best learning rate\n",
        "\n",
        "To find the ideal learning rate (the learning rate where the loss decreases the most during training), we're going to use the following steps:\n",
        "* A learning rate **callback*** - you can think of a callback as an extra piece of functionality, you can add to your model *while it's training.*\n",
        "* Another model (we could use the same one as above, but we're practicing building models here)\n",
        "* A modified loss curves plot."
      ],
      "metadata": {
        "id": "wPFb-xcTVvxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model (same as model_8)\n",
        "model_9 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_9.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Create a learning rate callback\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10 ** (epoch / 20))\n",
        "\n",
        "# 3. Fit the model (passing lr_scheduler callback)\n",
        "history_9 = model_9.fit(X_train, y_train, epochs=100, callbacks=[lr_scheduler])"
      ],
      "metadata": {
        "id": "oLjRs0JPXkS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkout the history\n",
        "pd.DataFrame(history_9.history).plot(figsize=(10, 7), xlabel=\"epochs\");"
      ],
      "metadata": {
        "id": "nKC23TJ0ZB1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning rate versus the loss\n",
        "lrs = 1e-4 * (10 ** (tf.range(100) / 20))\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.semilogx(lrs, history_9.history[\"loss\"])\n",
        "plt.xlabel(\"Learning Rate\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Learning rate vs. Loss\");"
      ],
      "metadata": {
        "id": "iGIfNommZfsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of other typical learning rates values:\n",
        "10 ** 0, 10 ** -1, 10 ** -2, 10 ** -3, 1e-4"
      ],
      "metadata": {
        "id": "U4UQ-30qaC_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate we used before\n",
        "10 ** -2"
      ],
      "metadata": {
        "id": "RVc1Gv9idMGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try using a higher *ideal* learning rate with the same model\n",
        "\n",
        "# Set the random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create the model\n",
        "model_10 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(4, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# 2. Compile the model with the ideal learning rate\n",
        "model_10.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.02),\n",
        "                 metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model for 20 epochs (5 less than before)\n",
        "history_10 = model_10.fit(X_train, y_train, epochs=20)"
      ],
      "metadata": {
        "id": "yGcgOqbYaDmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_10 on the test dataset\n",
        "model_10.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "BbZrvh5TdrSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_8 on the test dataset\n",
        "model_8.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "gqeUcrmBeCvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the decision boundaries for the training and test sets\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Train\")\n",
        "plot_decision_boundary(model_10, X=X_train, y=y_train)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Test\")\n",
        "plot_decision_boundary(model_10, X=X_test, y=y_test)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "tFpuDj1OeJ8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More classification evaluation metrics\n",
        "\n",
        "Alongside visualizing our model's results as much as possible, there are a handful of other classification evaluation methods & metrics you should be familiar with:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-Score\n",
        "* Confusion matrix\n",
        "* Classification report (from SciKit-Learn)"
      ],
      "metadata": {
        "id": "AMSHWt8Seoof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the accuracy of our model\n",
        "loss, accuracy = model_10.evaluate(X_test, y_test)\n",
        "print(f\"Model loss on the test set: {loss}\")\n",
        "print(f\"Model accuracy on the test set: {(accuracy * 100):.2f}%\")"
      ],
      "metadata": {
        "id": "H9sc7LVHzGag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about a confusion matrix?"
      ],
      "metadata": {
        "id": "A2C6LTMYzi7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Make predictions\n",
        "y_preds = model_10.predict(X_test)\n",
        "\n",
        "# Create confusion matrix\n",
        "confusion_matrix(y_test, y_preds)"
      ],
      "metadata": {
        "id": "Ob4bhCZrzrVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:10]"
      ],
      "metadata": {
        "id": "bm75JyX00Vs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds[:10]"
      ],
      "metadata": {
        "id": "dLPzTHdD0fBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oops... looks like our predictions array has come out in **prediction probability** form... the standard output from the sigmoid (or softmax) activation functions."
      ],
      "metadata": {
        "id": "7pdHI59p0hCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to binary format and view the first 10\n",
        "tf.math.round(y_preds)[:10]"
      ],
      "metadata": {
        "id": "YrdiG3Lq1Azw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a confusion matrix\n",
        "confusion_matrix(y_test, tf.math.round(y_preds))"
      ],
      "metadata": {
        "id": "d-kET1sg1LJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How about we pretiify our confusion matrix?"
      ],
      "metadata": {
        "id": "Aon0f_uT1mne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: the confusion matix code we're abput to write is a remix of scikit-learn's plot_confusion_matrix\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html#sklearn.metrics.plot_confusion_matrix\n",
        "\n",
        "import itertools\n",
        "\n",
        "figsize = (10, 10)\n",
        "\n",
        "# Create the confusion matrix\n",
        "cm = confusion_matrix(y_test, tf.math.round(y_preds))\n",
        "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize our confusion matrix\n",
        "n_classes = cm.shape[0]\n",
        "\n",
        "# Let's prettify it\n",
        "fig, ax = plt.subplots(figsize=figsize)\n",
        "# Create a matrix plot\n",
        "cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# Create classes\n",
        "classes = False\n",
        "\n",
        "if classes:\n",
        "    labels = classes\n",
        "else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "# Label the axes\n",
        "ax.set(title=\"Confusion Matrix\",\n",
        "       xlabel=\"Predicted Label\",\n",
        "       ylabel=\"True Label\",\n",
        "       xticks=np.arange(n_classes),\n",
        "       yticks=np.arange(n_classes),\n",
        "       xticklabels=labels,\n",
        "       yticklabels=labels)\n",
        "\n",
        "# Set x-axis labels to bottom\n",
        "ax.xaxis.set_label_position(\"bottom\")\n",
        "ax.xaxis.tick_bottom()\n",
        "\n",
        "# Adjust label size\n",
        "ax.yaxis.label.set_size(20)\n",
        "ax.xaxis.label.set_size(20)\n",
        "ax.title.set_size(20)\n",
        "\n",
        "# Set the threshold for different colors\n",
        "threshold = (cm.max() + cm.min()) / 2\n",
        "\n",
        "# Plot the text on each cell\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j] * 100:.1f}%)\",\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "             size=15)"
      ],
      "metadata": {
        "id": "psF_vtkMBh24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with a larger example (multiclass classification)\n",
        "\n",
        "When you have more than two classes as an option, it's known as **multi-class classification**.\n",
        "\n",
        "* This means if you have 3 different classes, it's multi-class classification.\n",
        "* It also means if you have 100 different classes, it's multi-class classification.\n",
        "\n",
        "To practice multi-class classification, we're going to build a neural network to classify images of different items of clothing."
      ],
      "metadata": {
        "id": "I-2xTc9oChI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# The data has already been sorted into training and test sets for us\n",
        "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "ALkUVwxgIB0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the first training example\n",
        "print(f\"Training sample:\\n{train_data[0]}\\n\")\n",
        "print(f\"Training label:\\n{train_labels[0]}\\n\")"
      ],
      "metadata": {
        "id": "A1YXRsAHJrd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of a single example\n",
        "train_data[0].shape, train_labels[0].shape"
      ],
      "metadata": {
        "id": "U2TTAOAuJ6h8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a single sample\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_data[7]);"
      ],
      "metadata": {
        "id": "rLlM1FllKW_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out sample's label\n",
        "train_labels[7]"
      ],
      "metadata": {
        "id": "hD5usPbKKmRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OHpCQQu7KulV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "02-neural-network-classification-with-tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMy0CkOMcfWYxOiwGf0Nc/L",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}